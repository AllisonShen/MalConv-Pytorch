{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vae.ipynb","provenance":[],"authorship_tag":"ABX9TyO0y7MbKowTUG9d/JvT1U/k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"wCMMXOJhzQ7v"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGcCWg4uyNNY"},"source":["#loading data\n","x_full_na = np.loadtxt(os.path.join(data_dir,'x_full.dat'), delimiter=',')\n","y_full_na = np.loadtxt('y_full.dat', delimiter=',')\n","\n","print(x_full_na.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VkML6Y81yvbx"},"source":["#variational autoencoders\n","from keras.layers import Lambda, Input, Dense\n","from keras.models import Model\n","\n","from keras.losses import mse, binary_crossentropy\n","from keras.utils import plot_model\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_curve\n","from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import argparse\n","import os\n","\n","def sampling(args):\n","  z_mean, z_log_var = args\n","  batch = K.shape(z_mean) [0]\n","  dim = K.int_shape(z_mean) [1]\n","  epsilon = K.random_normal(shape=(batch, dim)) #by default, random_normal has mean = 0 and std = 1.0\n","\n","  return z_mean + K.exp(0.5 * z_log_var) * epsilon\n","\n","# get dataset\n","X_train, X_test, y_train, y_test = train_test_split(x_full_na,y_full_na,test_size=0.2, shuffle=True)\n","X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n","X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n","\n","print(X_train.shape)\n","# reshape and normalization\n","image_size = X_train.shape[1]\n","original_dim = image_size \n","x_train = X_train /255\n","x_test = X_test /255\n","X_train = X_train.astype('float32') / 255\n","X_test = X_test.astype('float32') / 255\n","\n","\n","# network parameters and learning parameters\n","batch_size = 32\n","original_shape = X_train.shape[1:]\n","original_dim = 1006\n","latent_dim = 4\n","intermediate_dim = 128\n","final_dim = 64\n","epochs = 50\n","epsilon_std = 1.0\n","\n","\n","# encoder model\n","in_layer = Input(shape=original_shape)\n","x = Flatten()(in_layer)\n","h = Dense(intermediate_dim, activation='relu')(x)\n","h = Dense(final_dim, activation = 'relu')(h)\n","z_mean = Dense(latent_dim)(h)\n","z_log_var = Dense(latent_dim)(h)\n","\n","# sampling \n","z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var]) \n","\n","# instantiate encoder model\n","decoder_f = Dense(final_dim, activation='relu')\n","decoder_h = Dense(intermediate_dim, activation='relu')\n","decoder_mean = Dense(original_dim, activation='sigmoid')\n","\n","f_decoded = decoder_f(z)\n","h_decoded = decoder_h(f_decoded)\n","x_decoded_mean = decoder_mean(h_decoded)\n","x_decoded_img = Reshape(original_shape)(x_decoded_mean)\n","\n","# instantiate VAE model\n","vae = Model(in_layer, x_decoded_img)\n","\n","# Compute VAE loss\n","xent_loss = original_dim * binary_crossentropy(x, x_decoded_mean)\n","kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n","vae_loss = K.mean(xent_loss + kl_loss)\n","\n","vae.add_loss(vae_loss)\n","vae.compile(optimizer='rmsprop')\n","vae.summary()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RJqsDN_wy11E"},"source":["anomaly_test = x_train[y_train==1]\n","\n","vae.fit(x_train[y_train==0],\n","        shuffle=True,\n","        epochs=epochs,\n","        batch_size=batch_size,\n","        validation_data=(anomaly_test, None))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iY6kb0dRy7Qo"},"source":["# VAE loss\n","\n","\n","\n","# plot loss history\n","from sklearn.metrics import roc_auc_score, roc_curve\n","mse_score = np.concatenate([model_mse(X_test), model_mse(anomaly_test)],0)\n","true_label = [0]*X_test.shape[0]+[1]*anomaly_test.shape[0]\n","if roc_auc_score(true_label, mse_score)<0.5:\n","    mse_score *= -1\n","fpr, tpr, thresholds = roc_curve(true_label, mse_score)\n","auc_score = roc_auc_score(true_label, mse_score)\n","fig, ax1 = plt.subplots(1, 1, figsize = (8, 8))\n","ax1.plot(fpr, tpr, 'b.-', label = 'ROC Curve (%2.2f)' %  auc_score)\n","ax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\n","ax1.legend();\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFUwxZUwy-15"},"source":["# Visualization of latent space\n","z_mean, _, _ = encoder.predict(x_test, batch_size=batch_size)\n","plt.figure(figsize=(12, 10))\n","plt.scatter(z_mean[:, 0], z_mean[:, 1])\n","plt.xlabel(\"z[0]\")\n","plt.ylabel(\"z[1]\")\n","plt.title('Test Data Latent Space')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UNsJRGzHy_au"},"source":["# Visualization of latent space\n","z_mean, _, _ = encoder.predict(x_train, batch_size=batch_size)\n","plt.figure(figsize=(12, 10))\n","plt.scatter(z_mean[:, 0], z_mean[:, 1])\n","plt.xlabel(\"z[0]\")\n","plt.ylabel(\"z[1]\")\n","plt.title('Train Data Latent Space')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2hL8s2e6zM-D"},"source":[""],"execution_count":null,"outputs":[]}]}